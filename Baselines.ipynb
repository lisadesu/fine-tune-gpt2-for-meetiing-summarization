{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Baselines for dialogues summarization"
      ],
      "metadata": {
        "id": "ZDYsyfMuimye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rouge_score\n",
        "! pip install evaluate\n",
        "! pip install nltk\n",
        "\n",
        "import random\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import evaluate\n",
        "import rouge_score\n",
        "\n",
        "rouge_score = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "Scv5SS0WADwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "2Q2QwOIxKQcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test dataset loading"
      ],
      "metadata": {
        "id": "V_T7i1VPlDk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('ami_test_1024.csv')\n",
        "test_texts = test_data['text'].values\n",
        "test_summaries_extractive = test_data['extractive'].values\n",
        "test_summaries_abstractive = test_data['abstract'].values"
      ],
      "metadata": {
        "id": "1IcZM1wOAwgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rouge scoring"
      ],
      "metadata": {
        "id": "kJtbHnQXCP3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_rouge(predictions, golden):\n",
        "  metrics = rouge_score.compute(predictions=predictions, references=golden)\n",
        "  rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "  rouge_dict = dict((rn, round(metrics[rn] * 100, 2)) for rn in rouge_names)\n",
        "  return(rouge_dict)"
      ],
      "metadata": {
        "id": "iup9QybhCRaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstractive summarization baselines"
      ],
      "metadata": {
        "id": "QWiw4R28kjTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TL:DR"
      ],
      "metadata": {
        "id": "d35yWGDYD_A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers\n",
        "! pip install datasets\n",
        "\n",
        "import re\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import torch"
      ],
      "metadata": {
        "id": "56GEwVJqGHgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "w_Qt6MGrGomo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)"
      ],
      "metadata": {
        "id": "63ywUZvMGpDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use gpt2 model for summarization task we can add TL;DR: tag at the end of the input sequence:"
      ],
      "metadata": {
        "id": "Cx4dZb3ujGVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts_tldr = [t + ' TL;DR: ' for t in test_texts]"
      ],
      "metadata": {
        "id": "Y-6xkBGAF5L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tldr(text, taget):\n",
        "    index = text.find(taget)\n",
        "\n",
        "    return text[index + len(taget):].strip()"
      ],
      "metadata": {
        "id": "lAxNWeYCJb-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate results with top k approach"
      ],
      "metadata": {
        "id": "ryxt6rVqjYA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def top_k(text, model, max_length, top_k=0, temperature=None, target='TL;DR:'):\n",
        "   text = tokenizer(text, return_tensors=\"pt\")\n",
        "   X = text[\"input_ids\"].to(device)\n",
        "   a = text[\"attention_mask\"].to(device)\n",
        "   output = model.generate(X, attention_mask=a, max_length=1024, do_sample=True, top_k=top_k, no_repeat_ngram_size=3, temperature=temperature)\n",
        "   output = tokenizer.decode(output[0])\n",
        "   output = extract_tldr(output, target)\n",
        "   return ''.join(sent_tokenize(output)[:1]) # take only first sentence, since abstactive summaries from AMI present one-sentence headline"
      ],
      "metadata": {
        "id": "FgJXwliPINQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(top_k(test_texts_tldr[0], model, 1024, 2, 0.5, 'TL;DR:'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTIXPfbJHmHo",
        "outputId": "8e3a3436-09e4-4b35-f67c-0ccdd55a41c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The more buttons you can make a trendier design.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tldr_summaries = [top_k(t,model, 1024, 2, 0.5, 'TL;DR:') for t in tqdm(test_texts_tldr)]"
      ],
      "metadata": {
        "id": "MnCsFnmSKAcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouges_tldr = evaluate_rouge(tldr_summaries, test_summaries_abstractive)"
      ],
      "metadata": {
        "id": "1uvlTrLuMn5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouges_tldr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1084d55-9e08-4122-bfff-5be899b5d842",
        "id": "O2mJRJ70Mn5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 11.63, 'rouge2': 1.44, 'rougeL': 9.18, 'rougeLsum': 9.38}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TL;DR no hint"
      ],
      "metadata": {
        "id": "2OZecnO_MM0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_hint_summaries = [top_k(t,model, 1024, 2, 0.5, t) for t in tqdm(test_texts)]"
      ],
      "metadata": {
        "id": "4RkFxLo-MQn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_hint_rouges = evaluate_rouge(no_hint_summaries, test_summaries_abstractive)"
      ],
      "metadata": {
        "id": "kPWOp1SzNssw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_hint_rouges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdZgJMesOBz_",
        "outputId": "6962c01a-ed7a-4e2b-d7c7-ef73d8964c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 6.69, 'rouge2': 0.35, 'rougeL': 5.47, 'rougeLsum': 5.49}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extractive dialogue summarization baselines"
      ],
      "metadata": {
        "id": "EbdhUdEfkbW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LEAD-3 baseline"
      ],
      "metadata": {
        "id": "BZSHb57dAeAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def three_sentence_summary(text):\n",
        "    return \"\\n\".join(sent_tokenize(text)[:3])"
      ],
      "metadata": {
        "id": "YteBRcBHB8lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lead_3_summaries = [three_sentence_summary(t) for t in test_texts]"
      ],
      "metadata": {
        "id": "pFaMXi2_CIgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouges_lead3 = evaluate_rouge(lead_3_summaries, test_summaries_extractive)"
      ],
      "metadata": {
        "id": "abULYX2QCNMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouges_lead3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KTRRR7tCW4s",
        "outputId": "0dbaad8f-d1ee-44fb-8d3c-285a8b9cb68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 27.8, 'rouge2': 21.24, 'rougeL': 24.57, 'rougeLsum': 27.32}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random-3 baseline"
      ],
      "metadata": {
        "id": "psR3VHFOEzeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(101)"
      ],
      "metadata": {
        "id": "nYZoEBmlki4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_three_sentence_summary(text):\n",
        "    return \"\\n\".join(random.sample(sent_tokenize(text), 3))"
      ],
      "metadata": {
        "id": "4buA-ivkE3Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "three_random_summaries = [random_three_sentence_summary(t) for t in test_texts]"
      ],
      "metadata": {
        "id": "E5K5es-UFKWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouges_random3 = evaluate_rouge(three_random_summaries, test_summaries_extractive)"
      ],
      "metadata": {
        "id": "6ToaVzUQFfWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouges_random3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFvdxUJTFqeH",
        "outputId": "da81cfc1-4972-447d-e3a3-32a8c0679470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 24.69, 'rouge2': 14.35, 'rougeL': 19.09, 'rougeLsum': 23.22}"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TL-DR-3"
      ],
      "metadata": {
        "id": "6vRPXWjoOsgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_extractive(text, model, max_length, top_k=0, temperature=None, target='TL;DR:'):\n",
        "   text = tokenizer(text, return_tensors=\"pt\")\n",
        "   X = text[\"input_ids\"].to(device)\n",
        "   a = text[\"attention_mask\"].to(device)\n",
        "   output = model.generate(X, attention_mask=a, max_length=1024, do_sample=True, top_k=top_k, no_repeat_ngram_size=3, temperature=temperature)\n",
        "   output = tokenizer.decode(output[0])\n",
        "   output = extract_tldr(output, target)\n",
        "   return '\\n'.join(sent_tokenize(output)[:3]) # for extractive summaries take first 3 sentences"
      ],
      "metadata": {
        "id": "U6C6s3BZOwAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tldr_summaries_extractive = [top_k_extractive(t,model, 1024, 2, 0.5, 'TL;DR:') for t in tqdm(test_texts_tldr)]"
      ],
      "metadata": {
        "id": "dri44udJO1l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tldr_extractive_rouges = evaluate_rouge(tldr_summaries_extractive, test_summaries_extractive)"
      ],
      "metadata": {
        "id": "vUjwOFrIP0lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tldr_extractive_rouges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-hhYgo3Xea9",
        "outputId": "275e37db-e80b-423f-8247-cd9d8ae0d48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 22.8, 'rouge2': 4.72, 'rougeL': 14.96, 'rougeLsum': 21.65}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TL-DR-3 no hint Extractive"
      ],
      "metadata": {
        "id": "zxR2kJ2nR1f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nohint_summaries_extractive = [top_k_extractive(t,model, 1024, 2, 0.5, t) for t in tqdm(test_texts_tldr)]"
      ],
      "metadata": {
        "id": "C68XcVnoR5RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nohint_extractive_rouges = evaluate_rouge(nohint_summaries_extractive, test_summaries_extractive)"
      ],
      "metadata": {
        "id": "ZZRVnyygXmjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nohint_extractive_rouges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee193c2-5f49-4929-f2b4-9c63b6a0077f",
        "id": "T4zuI0ZTXmjS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 18.97, 'rouge2': 3.51, 'rougeL': 12.0, 'rougeLsum': 17.69}"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    }
  ]
}